{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tw5wTSakOJmd"
   },
   "source": [
    "# <font color = \"red\">[READ THIS] Before you start</font>\n",
    "Welcome to UpLevel mini-projects! In this series, you're challenged to independently work (with our guidance) with data that you will collect to UpLevel yourself. \n",
    "\n",
    "We hope you're excited to embark on this adventure.\n",
    "### Warning:\n",
    "This isn't just any coding course or programmes, where you receive helper code as you move from one code block to another. \n",
    "\n",
    "This is when things get <em>real</em>.\n",
    "\n",
    "In this project, you will receive instructions to execute a task along with an intended outcome. Most importantly, we will provide you with directions you can go to, to pick up code independently and implement it in this notebook.\n",
    "\n",
    "Don't worry though, we'll be dropping lots of resources you can consult and these readings will contain everything you need to succeed. You can also perform independent research to find answers independently. You just have to read closely and pick out the parts that make most sense. \n",
    "\n",
    "<strong>We make you do this not because we're lazy bastards but because being able to indepedently find code is a highly underrated skill and that's something all companies look out for.</strong>\n",
    "\n",
    "If you're really stuck and are on the verge of giving up, we gotchu fam. Head on over to our Telegram community at https://bit.ly/UpLevelSG and post your questions there. \n",
    "\n",
    "### What we'll be doing:\n",
    "In this project, we will do the following:\n",
    "\n",
    "1. <font color='orange'>[Google Colab]</font> Scrape and collect news articles from NewsWeek (Part I)\n",
    "2. <font color='orange'>[Google Colab]</font> Perform extractive summarization on collected articles (Part II) \n",
    "3. <font color='orange'>[Google Colab]</font> Perform abstractive summarization on collected articles (Part III) \n",
    "4. <font color='orange'>[Google Colab]</font> Comparing and analyzing the differences between the two kinds of summaries (Part IV)\n",
    "\n",
    "### Expectations:\n",
    "We're not going to sugarcoat it - it'll be challenging at times. You have to promise to put in the time and effort to UpLevel yourself. \n",
    "\n",
    "But we promise you that it'll ultimately be fun and rewarding, and you'll come out of it stronger and more confident than before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQJ-aWzaQ2WP"
   },
   "source": [
    "# Introduction\n",
    "<font color='green'>Summarizing notes and articles can be a drag, especially when you have to go through the entire document repeatedly to identify important point.</font>\n",
    "\n",
    "<font color='green'>You remember reading about summarization techniques in Natural Language Processing, which you think can be applied in your day-to-day.</font>\n",
    "\n",
    "<font color='green'>As such, you decided to try the new techniques on news articles that you intend to collect by yourself on Newsweek. \n",
    "</font>\n",
    "\n",
    "In this Part, we will do the following:\n",
    "1. Explore the HTML of Newsweek \n",
    "2. Scrape NewsWeek articles and summaries\n",
    "\n",
    "In this Part, we will teach you to scrape a very small number of articles from NewsWeek. We will then provide you with a pre-scraped CSV for subsequent portions. \n",
    "\n",
    "The reason for that was that we do not want to overload their servers. The main point of this Part is to teach you the principles of scraping and the thought processes behind it. \n",
    "\n",
    "As such, if you're already familiar with scraping and want to skip ahead, just click <a href=\"https://uplevelsg.s3-ap-southeast-1.amazonaws.com/df_part_i.csv\">here</a> to acquire the data.\n",
    "\n",
    "---\n",
    "\n",
    "<em>Disclaimer\n",
    "\n",
    "If the scraping portion doesn't work due to a change in Newsweek's HTML structure, and you got this notebook specifically because of the exciting scraping part - we're really sorry.\n",
    "\n",
    "Drop Jackie an email at jackie@uplevel.work and we'll do our best to either replace this project with another or issue you a full refund.</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJiPHTL4mPiV"
   },
   "source": [
    "### Step 1: Import libraries\n",
    "We'll be importing a few libraries for scraping:\n",
    "- requests\n",
    "- bs4\n",
    "- pandas as pd\n",
    "\n",
    "Useful reading for scraping: https://www.dataquest.io/blog/web-scraping-beautifulsoup/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "66dPLR2kQyq9"
   },
   "outputs": [],
   "source": [
    "# Step 1: Import your libraries\n",
    "import requests\n",
    "import bs4\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8l3LyUOimqqR"
   },
   "source": [
    "# Structure of NewsWeek\n",
    "We will be scraping news articles from Newsweek (https://www.newsweek.com/newsfeed). NewsWeek\n",
    "\n",
    "![NewsWeekStructure](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTextSummarizer/NewsWeekStructure.png)\n",
    "There are three components involved in the scraping:\n",
    "1. Listing pages containing article summaries\n",
    "2. Article summaries\n",
    "3. Article text\n",
    "\n",
    "In our scraping campaign, we will first go through pages of listings (1) containing summaries (2), and then collect the corresponding articles (3) within each article URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3quEFeXBzHm"
   },
   "source": [
    "# Test scraping one listings page\n",
    "We'll start with scraping the items from the first page (https://www.newsweek.com/newsfeed?page=1).\n",
    "\n",
    "Here's an example of 1 \"box\".\n",
    "\n",
    "![ListingItem](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTextSummarizer/ListingItem.png)\n",
    "\n",
    "1. category\n",
    "2. url\n",
    "3. title\n",
    "4. summary\n",
    "\n",
    "Each listings page contains 30 summaries but we'll start slowly first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6QVeMbu76YQ"
   },
   "source": [
    "### Step 2: Get the response of the first page of Newsweek listing\n",
    "We'll start with getting the response of the GET request that we make for \"https://www.newsweek.com/newsfeed?page=1\"\n",
    "\n",
    "Assign the results to a variable and check for the response code.\n",
    "\n",
    "Make sure it's 200! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AhfsWOrv75xH",
    "outputId": "d13d5c18-4734-4fa3-fdab-a751b8e898e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Make a request and check the response code\n",
    "url = \"https://www.newsweek.com/newsfeed?page=1\"\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKf64qGP-9-l"
   },
   "source": [
    "### [Optional] Modify headers for GET request\n",
    "Having trouble with your GET request, and getting a 403 Response? \n",
    "\n",
    "No worries, we got you. Sometimes, making a vanilla GET request leads to this response because the server things you're not legit. \n",
    "\n",
    "As such, you'll need to configure your call with by supplying a header. \n",
    "\n",
    "Define a header, where it is a dictionary containing a 'User-Agent' key. The value? \n",
    "\n",
    "Hint: It's the specs of a browser.\n",
    "\n",
    "<details>\n",
    "<summary>Click once for a massive hint</summary>\n",
    "<div><strong>Google \"How to use Python requests to fake a browser visit a.k.a and generate User Agent?\"</strong></div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-kN8Vyt_-9Pa",
    "outputId": "ae96c013-239c-41c0-c00b-5dd807840ef8"
   },
   "outputs": [],
   "source": [
    "# Add a headers option and make the GET request\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(url,headers=headers)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTVFPxvkAPZD"
   },
   "source": [
    "### Step 3: Load the response text into a BeautifulSoup object\n",
    "Once you have made a successful GET request and have the response, load the response text into a BeautifulSoup object.\n",
    "\n",
    "If you check the BeautifulSoup object, you should see something like this:\n",
    "\n",
    "![BeautifulSoupText](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTextSummarizer/BeautifulSoupText.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ihOg0YTMSI_Y",
    "outputId": "ab0bd60b-5527-423d-fae9-cbe6a59954fd"
   },
   "outputs": [],
   "source": [
    "# Step 3: Load the response text into a BeautifulSoup object\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(response.text,'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxks-KryCqNI"
   },
   "source": [
    "### Step 4: Check out the HTML of the listings page\n",
    "Let's go to the first page of the news. <strong>Make sure you're using Google Chrome.</strong>\n",
    "\n",
    "When you're there, hover over the title of the first news. Right click, and click \"Inspect\".\n",
    "\n",
    "If this is the first time you've tried it, you're in for a treat:\n",
    "\n",
    "![HTMLBreakdown](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTextSummarizer/HTMLBreakdown.png)\n",
    "\n",
    "What's happening here?\n",
    "\n",
    "Think of your webpage as composed of boxes within boxes within boxes. \n",
    "\n",
    "In the Newsweek page, you have one big box, containing 30 <font color='red'>boxes</font> belonging to the \"article\" HTML tag. \n",
    "\n",
    "In each of the <font color='red'>box</font>, you have smaller boxes.\n",
    "- <font color='green'>Image</font> (div)\n",
    "- <font color='blue'>A box</font> (div), containing\n",
    "  - <font color='yellow'>Category</font> (div)\n",
    "  - <font color='purple'>Title and URL to article</font> (h3)\n",
    "  - <font color='brown'>Summary</font> (div)\n",
    "\n",
    "We'll retrieve a list containing 30 boxes first, then rummage in the first box to locate the <font color='yellow'>Category</font>, <font color='purple'>Title and URL to article</font>, and <font color='brown'>Summary</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkljxrbqUQCS"
   },
   "source": [
    "### Step 5: Find all article tags in the BeautifulSoup object\n",
    "Let's use the .find_all method to get a list containing all \"article\" tags.\n",
    "\n",
    "You should end up with a list containing 30 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fs2ZYzOhSLAZ",
    "outputId": "053ebf15-bafa-4750-b83c-e9791d8feb39"
   },
   "outputs": [],
   "source": [
    "# Step 5: Get list of \"article\" HTML tags\n",
    "articlelist = soup.find_all('article')\n",
    "#articlelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e5wg-Fqc4ZJ"
   },
   "source": [
    "### Step 6: Get the first item in the list\n",
    "Declare a variable and assign the first item in the list to it.\n",
    "\n",
    "We'll start dissecting the first item first before creating a loop - we do have to identify where each piece of information is after all.\n",
    "\n",
    "The item starts with ```<article class=\"l3\">``` and ends with ```</article>```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zf9jgxxwSgb1",
    "outputId": "d45bff7b-4e2b-4555-d4a8-2606955b445e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<article class=\"l3\"><div class=\"image\">\n",
       "<picture class=\"mapping-small\" height=\"311\" width=\"466\">\n",
       "<source srcset=\"https://d.newsweek.com/en/full/1829666/joe-biden-stimulus-check-monthly-fourth.webp?w=466&amp;h=311&amp;l=68&amp;t=41&amp;f=55e07178a7f697464af03e2eb0fddc9a\" type=\"image/webp\"/><img alt=\"\" class=\"mapping-small\" height=\"311\" loading=\"lazy\" src=\"https://d.newsweek.com/en/full/1829666/joe-biden-stimulus-check-monthly-fourth.jpg?w=466&amp;h=311&amp;l=68&amp;t=41&amp;f=55e07178a7f697464af03e2eb0fddc9a\" width=\"466\"/>\n",
       "</picture>\n",
       "<a class=\"zero\" href=\"/fourth-stimulus-check-update-2000-monthly-payment-petition-hits-24-million-signatures-1603975\">Fourth Stimulus Check Update: $2,000 Monthly Payment Petition Gains Support</a></div><div class=\"inner\"><div class=\"category\"><a href=\"/us\">U.S.</a></div><h3><a href=\"/fourth-stimulus-check-update-2000-monthly-payment-petition-hits-24-million-signatures-1603975\">Fourth Stimulus Check Update: $2,000 Monthly Payment Petition Gains Support</a></h3><div class=\"summary\">If the petition hits its goal of 3 million signatures, it will become one of the most signed petitions on Change.org.</div></div>\n",
       "</article>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Get the first item\n",
    "firstarticle = articlelist[0]\n",
    "firstarticle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k16PzoXrfVQp"
   },
   "source": [
    "### Step 7: Find \"category\"\n",
    "First up, let's look for the \"category\". \n",
    "\n",
    "Use the .find method on your first item to look for the div tag that belongs to the \"category\" class. \n",
    "\n",
    "Once you find the div, get only the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "rs0l96nTThUh",
    "outputId": "c6b5f752-1b31-4389-ba9a-686ad90d0160"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U.S.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7a: Find \"category\"\n",
    "firstarticle.find('div',{'class':'category'})\n",
    "\n",
    "# Step 7b: Get only the text\n",
    "firstarticle.find('div',{'class':'category'}).get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxJDz1NMlZMS"
   },
   "source": [
    "### Step 8: Find the URL to article\n",
    "The URL to the full article text contains the string \"/a-news-article-that-you-attach-to-the-end\". You'll have to dig to find the correct HTML tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAcEwHfIm75B"
   },
   "source": [
    "<details>\n",
    "<summary>Click here once if you're stuck</summary>\n",
    "<div><strong>Google \"get href from anchor tag beautifulsoup\"</strong></div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "BKni2itxTYmq",
    "outputId": "739baf78-d001-4a51-c717-ddd27190ad7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h3><a href=\"/fourth-stimulus-check-update-2000-monthly-payment-petition-hits-24-million-signatures-1603975\">Fourth Stimulus Check Update: $2,000 Monthly Payment Petition Gains Support</a></h3>,\n",
       " <h3><a href=\"/dave-portnoy-shouts-fox-business-host-air-over-meme-stock-trading-1603994\">Dave Portnoy Shouts At Fox Business Host On Air Over Meme Stock Trading</a></h3>,\n",
       " <h3><a href=\"/teacher-forced-remove-giant-swastika-pool-bottom-1603961\">Teacher Forced to Remove Giant Swastika from Pool Bottom</a></h3>,\n",
       " <h3><a href=\"/mcconnell-biden-isnt-serious-about-bipartisanship-after-infrastructure-bill-veto-threat-1603996\">McConnell Says Biden Isn't 'Serious' About Bipartisanship After Veto Threat</a></h3>,\n",
       " <h3><a href=\"/hawley-condemns-canadas-arrest-church-leaders-asks-us-support-1603921\">Hawley Condemns Canada's Clampdown on Churches During COVID-19</a></h3>,\n",
       " <h3><a href=\"/20-highest-grossing-disney-movies-all-time-star-wars-frozen-1600957\">20 Highest Grossing Disney Movies of All Time</a></h3>,\n",
       " <h3><a href=\"/brandeis-lists-trigger-warning-among-violent-words-due-connection-guns-1603988\">Brandeis Says 'Trigger Warning' Is Violent Word Due to 'Connection to Guns'</a></h3>,\n",
       " <h3><a href=\"/radio-host-danny-parkins-raises-660k-nonprofit-supermarket-24-hour-radiothon-1603986\">Radio Host Raises $660k for Nonprofit Supermarket in 24-Hour Radiothon</a></h3>,\n",
       " <h3><a href=\"/why-im-leaving-mumford-sons-opinion-1603978\">Why I'm Leaving Mumford &amp; Sons</a></h3>,\n",
       " <h3><a href=\"/statue-george-floyd-vandalized-day-before-chauvin-sentencing-1603980\">Statue of George Floyd Vandalized Day Before Chauvin Sentencing</a></h3>,\n",
       " <h3><a href=\"/man-proposing-haunted-hill-discovers-ring-mysteriously-missing-1603959\">Man Proposing on 'Haunted Hill' Discovers Ring Is Mysteriously Missing</a></h3>,\n",
       " <h3><a href=\"/violence-non-violence-transforming-america-inside-out-opinion-1603972\">Violence to Non-violence: Transforming America from the Inside Out</a></h3>,\n",
       " <h3><a href=\"/kroger-shooter-gregory-bush-gets-life-sentence-hate-crime-killings-1603973\">Kroger Shooter Gregory A. Bush Gets Life Sentence for Hate Crime Killings</a></h3>,\n",
       " <h3><a href=\"/disney-guest-forced-change-inappropriate-outfit-adds-fuel-free-shirt-theory-1603964\">Disney Guest Forced to Change Outfit Adds Fuel to 'Free Shirt' Theory</a></h3>,\n",
       " <h3><a href=\"/msnbcs-joy-reid-criticized-separating-critical-race-theory-intersectionality-1603937\">Joy Reid Criticized for Separating Critical Race Theory, Intersectionality</a></h3>,\n",
       " <h3><a href=\"/donald-trump-reacts-rudy-giulianis-law-suspension-says-all-new-york-out-control-1603968\">Trump Reacts to Giuliani's Law Suspension: 'New York is Out of Control'</a></h3>,\n",
       " <h3><a href=\"/russia-reports-over-20k-new-covid-cases-highest-total-since-january-1603951\">Russia Reports Over 20K New COVID Cases, Highest Total Since January</a></h3>,\n",
       " <h3><a href=\"/uber-pay-13m-back-wages-over-2300-seattle-area-workers-1603948\">Uber to Pay $1.3M in Back Wages to Over 2,300 Seattle-Area Workers</a></h3>,\n",
       " <h3><a href=\"/wendy-davis-others-sue-trump-train-bunch-surrounding-biden-bus-highway-1603947\">Wendy Davis, Others Sue 'Trump Train' Bunch for Surrounding Biden Bus</a></h3>,\n",
       " <h3><a href=\"/still-best-kfc-employee-shows-how-mashed-potatoes-are-made-some-are-not-happy-1603932\">KFC Employee Shows How Mashed Potatoes Are Made and Some Are Not Happy</a></h3>,\n",
       " <h3><a href=\"/biden-tough-path-building-better-belt-road-china-1603929\">Biden Faces Tough Path to Building A Better Belt and Road than China</a></h3>,\n",
       " <h3><a href=\"/can-biden-putin-ease-nuclear-dangers-like-reagan-gorbachev-opinion-1603945\">Can Biden and Putin Ease Nuclear Dangers Like Reagan and Gorbachev?</a></h3>,\n",
       " <h3><a href=\"/businesses-wary-workers-demands-are-reluctant-hire-fed-president-says-1603940\">Businesses, Wary of Workers' Demands, Are Reluctant to Hire: Fed President</a></h3>,\n",
       " <h3><a href=\"/justice-department-admits-its-unprepared-implement-body-cameras-fbi-atf-agents-1603931\">Justice Department Admits It's 'Unprepared' to Implement Body Cameras</a></h3>,\n",
       " <h3><a href=\"/exorcism-lumber-home-depot-aisle-prompts-groups-removal-1603942\">Exorcism for Lumber in Home Depot Aisle Prompts Group's Removal</a></h3>,\n",
       " <h3><a href=\"/ncaa-could-keep-rules-banning-pay-play-recruiting-incentives-after-scotus-ruling-1603925\">NCAA Could Keep Rules Banning Recruiting Incentives After SCOTUS Ruling</a></h3>,\n",
       " <h3><a href=\"/one-us-largest-unions-votes-make-amazon-priority-unionization-1603935\">One of U.S. Largest Unions Votes to Make Amazon Priority for Unionization</a></h3>,\n",
       " <h3><a href=\"/viral-therapist-shows-audacity-men-dating-apps-including-requests-submissive-1603926\">Viral Therapist Shows 'Audacity' of Men on Dating Apps</a></h3>,\n",
       " <h3><a href=\"/trump-calls-mcbrooms-michigan-election-report-cover-asks-supporters-call-his-office-1603909\">Trump Calls McBroom's Michigan Election Report a 'Cover Up'</a></h3>,\n",
       " <h3><a href=\"/weed-cookies-that-resemble-famous-snack-brands-prompt-concerns-over-targeting-children-1603907\">Weed Cookies That Resemble Famous Snack Brands Prompt Concerns</a></h3>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 8: Find the URL\n",
    "soup.find_all('h3')\n",
    "#find_all_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all('h3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKQoqhw2nD_L"
   },
   "source": [
    "### Step 9: Find the title\n",
    "The title of the article is found in the H3 tag - retrieve it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3><a href=\"/fourth-stimulus-check-update-2000-monthly-payment-petition-hits-24-million-signatures-1603975\">Fourth Stimulus Check Update: $2,000 Monthly Payment Petition Gains Support</a></h3>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstarticle.find('h3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Wj_Kout-TcoU",
    "outputId": "613b029d-3900-4a98-855b-9ebe6fabd25c"
   },
   "outputs": [],
   "source": [
    "# Step 9: Get the title of the article in the first box\n",
    "soup.get('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARmTyS3ZoDab"
   },
   "source": [
    "### Step 10: Find the summary\n",
    "You'll have to find the summary text as well.\n",
    "\n",
    "Repeat what you did for Step 7, since the summary is hidden in the div with \"summary\" class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0qbcZOhOT8Uu",
    "outputId": "4518e19c-eaa0-4375-b665-8e605329ea5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If the petition hits its goal of 3 million signatures, it will become one of the most signed petitions on Change.org.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 10a: Find the div with the \"summary\" class\n",
    "firstarticle.find('div',{'class':'summary'})\n",
    "# Step 10b: Get the text\n",
    "firstarticle.find('div',{'class':'summary'}).get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtl0bTJZpL_n"
   },
   "source": [
    "### Step 11: Loop through all of the 30 boxes\n",
    "Well done, you. You have successfully identified how to retrieve the four pieces of information that we need from one box.\n",
    "\n",
    "Declare four empty lists, and let's build a for loop to loop through each item from the list you got from Step 5.\n",
    "\n",
    "Append the four items to their appropriate list - we'll need them to build a DataFrame later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvgJKjBIpzHk"
   },
   "source": [
    "<details>\n",
    "<summary>Stuck? Click here once for pseudocode</summary>\n",
    "<ol>\n",
    "  <li>Declare four empty lists - one for category, url, title, and summary</li>\n",
    "  <li>Use a for loop to loop through the list you got from Step 5. In each loop:</li>\n",
    "  <ul>\n",
    "    <li>Find the category of the box, and append into its list</li>\n",
    "    <li>Find the URL of the main article, and append into its list</li>\n",
    "    <li>Find the title of the box, and append it into its list</li>\n",
    "    <li>Find the summary of the box, and append it into its list</li>\n",
    "  </ul>\n",
    "</ol>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DupQ-urnUFX1"
   },
   "outputs": [],
   "source": [
    "# Step 11: Loop through all the 30 boxes and append the four items into lists\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "category = []\n",
    "URL = []\n",
    "title = []\n",
    "summary = []\n",
    "for div in soup.find_all('div', attrs={'class':'category'}):\n",
    "    category.append(div.text)\n",
    "for div in soup.find_all('h3'):\n",
    "    URL.append(div.find('a')['href'])\n",
    "for div in soup.find_all('h3'):\n",
    "    title.append(div.text)\n",
    "for div in soup.find_all('div', attrs={'class':'summary'}):\n",
    "    summary.append(div.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 30, 30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(category),len(URL),len(title),len(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJxoNdjlqoEV"
   },
   "source": [
    "### Step 12: Build a test DataFrame\n",
    "With the four lists of 30 items each, build a DataFrame. You'll see something like this:\n",
    "\n",
    "![TestDataFrame](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTextSummarizer/TestDataFrame.png)\n",
    "\n",
    "Expect:\n",
    "- 30 rows\n",
    "- 4 columns\n",
    "\n",
    "<strong>Don't panic if your DataFrame looks differently from ours, since news get updated all the time.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 910
    },
    "id": "XMJnDcZMU716",
    "outputId": "e75ffcd8-0b12-4bf0-fe16-6a647d5cd5ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>/fourth-stimulus-check-update-2000-monthly-pay...</td>\n",
       "      <td>Fourth Stimulus Check Update: $2,000 Monthly P...</td>\n",
       "      <td>If the petition hits its goal of 3 million sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>News</td>\n",
       "      <td>/dave-portnoy-shouts-fox-business-host-air-ove...</td>\n",
       "      <td>Dave Portnoy Shouts At Fox Business Host On Ai...</td>\n",
       "      <td>\"You're being a moron,\" Barstool Sports founde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>World</td>\n",
       "      <td>/teacher-forced-remove-giant-swastika-pool-bot...</td>\n",
       "      <td>Teacher Forced to Remove Giant Swastika from P...</td>\n",
       "      <td>A Brazilian history teacher has been forced to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>News</td>\n",
       "      <td>/mcconnell-biden-isnt-serious-about-bipartisan...</td>\n",
       "      <td>McConnell Says Biden Isn't 'Serious' About Bip...</td>\n",
       "      <td>When asked if he would sign the infrastructure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>News</td>\n",
       "      <td>/hawley-condemns-canadas-arrest-church-leaders...</td>\n",
       "      <td>Hawley Condemns Canada's Clampdown on Churches...</td>\n",
       "      <td>Missouri Senator Josh Hawley released a letter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Culture</td>\n",
       "      <td>/20-highest-grossing-disney-movies-all-time-st...</td>\n",
       "      <td>20 Highest Grossing Disney Movies of All Time</td>\n",
       "      <td>\"Star Wars,\" \"Toy Story,\" Avengers, plus both ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>/brandeis-lists-trigger-warning-among-violent-...</td>\n",
       "      <td>Brandeis Says 'Trigger Warning' Is Violent Wor...</td>\n",
       "      <td>The list of other violent and oppressive words...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>News</td>\n",
       "      <td>/radio-host-danny-parkins-raises-660k-nonprofi...</td>\n",
       "      <td>Radio Host Raises $660k for Nonprofit Supermar...</td>\n",
       "      <td>\"You guys crushed it,\" Parkins said on air Thu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Opinion</td>\n",
       "      <td>/why-im-leaving-mumford-sons-opinion-1603978</td>\n",
       "      <td>Why I'm Leaving Mumford &amp; Sons</td>\n",
       "      <td>The only way forward for me is to leave the ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>News</td>\n",
       "      <td>/statue-george-floyd-vandalized-day-before-cha...</td>\n",
       "      <td>Statue of George Floyd Vandalized Day Before C...</td>\n",
       "      <td>According to police, Floyd's face and the insc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>News</td>\n",
       "      <td>/man-proposing-haunted-hill-discovers-ring-mys...</td>\n",
       "      <td>Man Proposing on 'Haunted Hill' Discovers Ring...</td>\n",
       "      <td>While George Goddard and his now-fiance Isobel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Opinion</td>\n",
       "      <td>/violence-non-violence-transforming-america-in...</td>\n",
       "      <td>Violence to Non-violence: Transforming America...</td>\n",
       "      <td>Our enlightened ideals have always been accomp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>News</td>\n",
       "      <td>/kroger-shooter-gregory-bush-gets-life-sentenc...</td>\n",
       "      <td>Kroger Shooter Gregory A. Bush Gets Life Sente...</td>\n",
       "      <td>When a white man drew his gun, Bush reportedly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>News</td>\n",
       "      <td>/disney-guest-forced-change-inappropriate-outf...</td>\n",
       "      <td>Disney Guest Forced to Change Outfit Adds Fuel...</td>\n",
       "      <td>Another TikToker has opened up about her exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>News</td>\n",
       "      <td>/msnbcs-joy-reid-criticized-separating-critica...</td>\n",
       "      <td>Joy Reid Criticized for Separating Critical Ra...</td>\n",
       "      <td>Some viewers were quick to disagree with Reid,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>News</td>\n",
       "      <td>/donald-trump-reacts-rudy-giulianis-law-suspen...</td>\n",
       "      <td>Trump Reacts to Giuliani's Law Suspension: 'Ne...</td>\n",
       "      <td>\"Can you believe that New York wants to strip ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>World</td>\n",
       "      <td>/russia-reports-over-20k-new-covid-cases-highe...</td>\n",
       "      <td>Russia Reports Over 20K New COVID Cases, Highe...</td>\n",
       "      <td>Only 20.7 million people, 14 percent of the po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>News</td>\n",
       "      <td>/uber-pay-13m-back-wages-over-2300-seattle-are...</td>\n",
       "      <td>Uber to Pay $1.3M in Back Wages to Over 2,300 ...</td>\n",
       "      <td>Uber is to pay a total of $3.4 million to arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>/wendy-davis-others-sue-trump-train-bunch-surr...</td>\n",
       "      <td>Wendy Davis, Others Sue 'Trump Train' Bunch fo...</td>\n",
       "      <td>The suit alleges the \"Trump Train\" group viola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>/still-best-kfc-employee-shows-how-mashed-pota...</td>\n",
       "      <td>KFC Employee Shows How Mashed Potatoes Are Mad...</td>\n",
       "      <td>\"I'm pretty sure that's the same way they make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>World</td>\n",
       "      <td>/biden-tough-path-building-better-belt-road-ch...</td>\n",
       "      <td>Biden Faces Tough Path to Building A Better Be...</td>\n",
       "      <td>Discussing President Joe Biden's \"Build Back B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Opinion</td>\n",
       "      <td>/can-biden-putin-ease-nuclear-dangers-like-rea...</td>\n",
       "      <td>Can Biden and Putin Ease Nuclear Dangers Like ...</td>\n",
       "      <td>All we need is for our leaders today to show t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Business</td>\n",
       "      <td>/businesses-wary-workers-demands-are-reluctant...</td>\n",
       "      <td>Businesses, Wary of Workers' Demands, Are Relu...</td>\n",
       "      <td>\"We really need an economy that works for ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>/justice-department-admits-its-unprepared-impl...</td>\n",
       "      <td>Justice Department Admits It's 'Unprepared' to...</td>\n",
       "      <td>The audit report urged the Justice Department ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>/exorcism-lumber-home-depot-aisle-prompts-grou...</td>\n",
       "      <td>Exorcism for Lumber in Home Depot Aisle Prompt...</td>\n",
       "      <td>Police received a bizarre call that an exorcis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>News</td>\n",
       "      <td>/ncaa-could-keep-rules-banning-pay-play-recrui...</td>\n",
       "      <td>NCAA Could Keep Rules Banning Recruiting Incen...</td>\n",
       "      <td>The NCAA is working toward a solution for name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>News</td>\n",
       "      <td>/one-us-largest-unions-votes-make-amazon-prior...</td>\n",
       "      <td>One of U.S. Largest Unions Votes to Make Amazo...</td>\n",
       "      <td>The International Brotherhood of Teamsters, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Culture</td>\n",
       "      <td>/viral-therapist-shows-audacity-men-dating-app...</td>\n",
       "      <td>Viral Therapist Shows 'Audacity' of Men on Dat...</td>\n",
       "      <td>The TikTok community can't get enough of Katie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Politics</td>\n",
       "      <td>/trump-calls-mcbrooms-michigan-election-report...</td>\n",
       "      <td>Trump Calls McBroom's Michigan Election Report...</td>\n",
       "      <td>In the statement, the former president also re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>News</td>\n",
       "      <td>/weed-cookies-that-resemble-famous-snack-brand...</td>\n",
       "      <td>Weed Cookies That Resemble Famous Snack Brands...</td>\n",
       "      <td>\"This is extremely discouraging and alarming t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category                                                url  \\\n",
       "0       U.S.  /fourth-stimulus-check-update-2000-monthly-pay...   \n",
       "1       News  /dave-portnoy-shouts-fox-business-host-air-ove...   \n",
       "2      World  /teacher-forced-remove-giant-swastika-pool-bot...   \n",
       "3       News  /mcconnell-biden-isnt-serious-about-bipartisan...   \n",
       "4       News  /hawley-condemns-canadas-arrest-church-leaders...   \n",
       "5    Culture  /20-highest-grossing-disney-movies-all-time-st...   \n",
       "6       U.S.  /brandeis-lists-trigger-warning-among-violent-...   \n",
       "7       News  /radio-host-danny-parkins-raises-660k-nonprofi...   \n",
       "8    Opinion       /why-im-leaving-mumford-sons-opinion-1603978   \n",
       "9       News  /statue-george-floyd-vandalized-day-before-cha...   \n",
       "10      News  /man-proposing-haunted-hill-discovers-ring-mys...   \n",
       "11   Opinion  /violence-non-violence-transforming-america-in...   \n",
       "12      News  /kroger-shooter-gregory-bush-gets-life-sentenc...   \n",
       "13      News  /disney-guest-forced-change-inappropriate-outf...   \n",
       "14      News  /msnbcs-joy-reid-criticized-separating-critica...   \n",
       "15      News  /donald-trump-reacts-rudy-giulianis-law-suspen...   \n",
       "16     World  /russia-reports-over-20k-new-covid-cases-highe...   \n",
       "17      News  /uber-pay-13m-back-wages-over-2300-seattle-are...   \n",
       "18      U.S.  /wendy-davis-others-sue-trump-train-bunch-surr...   \n",
       "19      U.S.  /still-best-kfc-employee-shows-how-mashed-pota...   \n",
       "20     World  /biden-tough-path-building-better-belt-road-ch...   \n",
       "21   Opinion  /can-biden-putin-ease-nuclear-dangers-like-rea...   \n",
       "22  Business  /businesses-wary-workers-demands-are-reluctant...   \n",
       "23      U.S.  /justice-department-admits-its-unprepared-impl...   \n",
       "24      U.S.  /exorcism-lumber-home-depot-aisle-prompts-grou...   \n",
       "25      News  /ncaa-could-keep-rules-banning-pay-play-recrui...   \n",
       "26      News  /one-us-largest-unions-votes-make-amazon-prior...   \n",
       "27   Culture  /viral-therapist-shows-audacity-men-dating-app...   \n",
       "28  Politics  /trump-calls-mcbrooms-michigan-election-report...   \n",
       "29      News  /weed-cookies-that-resemble-famous-snack-brand...   \n",
       "\n",
       "                                                title  \\\n",
       "0   Fourth Stimulus Check Update: $2,000 Monthly P...   \n",
       "1   Dave Portnoy Shouts At Fox Business Host On Ai...   \n",
       "2   Teacher Forced to Remove Giant Swastika from P...   \n",
       "3   McConnell Says Biden Isn't 'Serious' About Bip...   \n",
       "4   Hawley Condemns Canada's Clampdown on Churches...   \n",
       "5       20 Highest Grossing Disney Movies of All Time   \n",
       "6   Brandeis Says 'Trigger Warning' Is Violent Wor...   \n",
       "7   Radio Host Raises $660k for Nonprofit Supermar...   \n",
       "8                      Why I'm Leaving Mumford & Sons   \n",
       "9   Statue of George Floyd Vandalized Day Before C...   \n",
       "10  Man Proposing on 'Haunted Hill' Discovers Ring...   \n",
       "11  Violence to Non-violence: Transforming America...   \n",
       "12  Kroger Shooter Gregory A. Bush Gets Life Sente...   \n",
       "13  Disney Guest Forced to Change Outfit Adds Fuel...   \n",
       "14  Joy Reid Criticized for Separating Critical Ra...   \n",
       "15  Trump Reacts to Giuliani's Law Suspension: 'Ne...   \n",
       "16  Russia Reports Over 20K New COVID Cases, Highe...   \n",
       "17  Uber to Pay $1.3M in Back Wages to Over 2,300 ...   \n",
       "18  Wendy Davis, Others Sue 'Trump Train' Bunch fo...   \n",
       "19  KFC Employee Shows How Mashed Potatoes Are Mad...   \n",
       "20  Biden Faces Tough Path to Building A Better Be...   \n",
       "21  Can Biden and Putin Ease Nuclear Dangers Like ...   \n",
       "22  Businesses, Wary of Workers' Demands, Are Relu...   \n",
       "23  Justice Department Admits It's 'Unprepared' to...   \n",
       "24  Exorcism for Lumber in Home Depot Aisle Prompt...   \n",
       "25  NCAA Could Keep Rules Banning Recruiting Incen...   \n",
       "26  One of U.S. Largest Unions Votes to Make Amazo...   \n",
       "27  Viral Therapist Shows 'Audacity' of Men on Dat...   \n",
       "28  Trump Calls McBroom's Michigan Election Report...   \n",
       "29  Weed Cookies That Resemble Famous Snack Brands...   \n",
       "\n",
       "                                              summary  \n",
       "0   If the petition hits its goal of 3 million sig...  \n",
       "1   \"You're being a moron,\" Barstool Sports founde...  \n",
       "2   A Brazilian history teacher has been forced to...  \n",
       "3   When asked if he would sign the infrastructure...  \n",
       "4   Missouri Senator Josh Hawley released a letter...  \n",
       "5   \"Star Wars,\" \"Toy Story,\" Avengers, plus both ...  \n",
       "6   The list of other violent and oppressive words...  \n",
       "7   \"You guys crushed it,\" Parkins said on air Thu...  \n",
       "8   The only way forward for me is to leave the ba...  \n",
       "9   According to police, Floyd's face and the insc...  \n",
       "10  While George Goddard and his now-fiance Isobel...  \n",
       "11  Our enlightened ideals have always been accomp...  \n",
       "12  When a white man drew his gun, Bush reportedly...  \n",
       "13  Another TikToker has opened up about her exper...  \n",
       "14  Some viewers were quick to disagree with Reid,...  \n",
       "15  \"Can you believe that New York wants to strip ...  \n",
       "16  Only 20.7 million people, 14 percent of the po...  \n",
       "17  Uber is to pay a total of $3.4 million to arou...  \n",
       "18  The suit alleges the \"Trump Train\" group viola...  \n",
       "19  \"I'm pretty sure that's the same way they make...  \n",
       "20  Discussing President Joe Biden's \"Build Back B...  \n",
       "21  All we need is for our leaders today to show t...  \n",
       "22  \"We really need an economy that works for ever...  \n",
       "23  The audit report urged the Justice Department ...  \n",
       "24  Police received a bizarre call that an exorcis...  \n",
       "25  The NCAA is working toward a solution for name...  \n",
       "26  The International Brotherhood of Teamsters, wh...  \n",
       "27  The TikTok community can't get enough of Katie...  \n",
       "28  In the statement, the former president also re...  \n",
       "29  \"This is extremely discouraging and alarming t...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 12: Build a DataFrame with the lists\n",
    "dfl = {'category':category,'url':URL,'title':title,'summary':summary}\n",
    "df = pd.DataFrame(dfl)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjHi7z6Hslxt"
   },
   "source": [
    "# Scrape 50 pages of listings\n",
    "Now that we've figured out how to scrape one page, let's scrape 50 pages.\n",
    "\n",
    "At the end, we'll have 1,500 rows of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVeCG3Rws_AE"
   },
   "source": [
    "### Step 13: Repeat Steps 2-12 and scale to 50 pages\n",
    "Modify Step 12 such that you acquire the listings information from 50 pages, instead of one page alone. \n",
    "\n",
    "You'll need to have two for loops instead of one, where you will exploit a URL pattern to move from one page to the next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Os97MeBnthPD"
   },
   "source": [
    "<details>\n",
    "<summary>Stuck AGAIN? Click here once for pseudocode</summary>\n",
    "<ol>\n",
    "  <li>Declare four empty lists - one for category, url, title, and summary</li>\n",
    "  <li>Declare a base URL for each page</li>\n",
    "  <li>Use a for loop to loop a range from 1 to 51. In each loop:</li>\n",
    "  <ol type ='a'>\n",
    "    <li>Declare a variable containing the URL for the page to be scraped, page_num=???</li>\n",
    "    <li>Make a GET request (don't forget the headers)</li>\n",
    "    <li>Store the text of the GET response in a BeautifulSoup object</li>\n",
    "    <li>Get a list of all the \"article\" tags</li>    \n",
    "    <li>Use a for loop to loop through the list of articles. In each for loop:</li>\n",
    "    <ul>\n",
    "      <li>Find the category of the box, and append into its list</li>\n",
    "      <li>Find the URL of the main article, and append into its list</li>\n",
    "      <li>Find the title of the box, and append it into its list</li>\n",
    "      <li>Find the summary of the box, and append it into its list</li>\n",
    "    </ul>\n",
    "  </ol>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwLXlQUKVNMM",
    "outputId": "e694ecca-2405-4067-a3f8-b0694c8130e2"
   },
   "outputs": [],
   "source": [
    "# Step 13: Loop through 50 pages of listings and store category, URL, title, and summary in lists\n",
    "category = []\n",
    "URL = []\n",
    "title = []\n",
    "summary = []\n",
    "page = range(1,51)\n",
    "url = \"https://www.newsweek.com/newsfeed?page=1\".format(i)\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}\n",
    "response = requests.get(url,headers=headers)\n",
    "soup = BeautifulSoup(response.text,'html.parser')\n",
    "articlelist = soup.find_all('article')\n",
    "for i in page:\n",
    "    url\n",
    "    response\n",
    "    soup\n",
    "    for div in soup.find_all('div', attrs={'class':'category'}):\n",
    "        category.append(div.text)\n",
    "    for div in soup.find_all('h3'):\n",
    "        URL.append(div.find('a')['href'])\n",
    "    for div in soup.find_all('h3'):\n",
    "        title.append(div.text)\n",
    "    for div in soup.find_all('div', attrs={'class':'summary'}):\n",
    "        summary.append(div.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(category),len(URL),len(title),len(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGqdY1MWvRtX"
   },
   "source": [
    "### Step 14: Create a DataFrame with the four lists\n",
    "After you scrape all of the information you need from the 50 pages, create a DataFrame like you did in Step 12.\n",
    "\n",
    "Your DataFrame will contain the following:\n",
    "- 1,500 rows\n",
    "- 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "gRiF1Oj9Yhw5",
    "outputId": "9a7fcd1a-63fa-4975-88aa-4f6957f76a09"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>/fourth-stimulus-check-update-2000-monthly-pay...</td>\n",
       "      <td>Fourth Stimulus Check Update: $2,000 Monthly P...</td>\n",
       "      <td>If the petition hits its goal of 3 million sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>News</td>\n",
       "      <td>/dave-portnoy-shouts-fox-business-host-air-ove...</td>\n",
       "      <td>Dave Portnoy Shouts At Fox Business Host On Ai...</td>\n",
       "      <td>\"You're being a moron,\" Barstool Sports founde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>World</td>\n",
       "      <td>/teacher-forced-remove-giant-swastika-pool-bot...</td>\n",
       "      <td>Teacher Forced to Remove Giant Swastika from P...</td>\n",
       "      <td>A Brazilian history teacher has been forced to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>News</td>\n",
       "      <td>/mcconnell-biden-isnt-serious-about-bipartisan...</td>\n",
       "      <td>McConnell Says Biden Isn't 'Serious' About Bip...</td>\n",
       "      <td>When asked if he would sign the infrastructure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>News</td>\n",
       "      <td>/hawley-condemns-canadas-arrest-church-leaders...</td>\n",
       "      <td>Hawley Condemns Canada's Clampdown on Churches...</td>\n",
       "      <td>Missouri Senator Josh Hawley released a letter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>News</td>\n",
       "      <td>/ncaa-could-keep-rules-banning-pay-play-recrui...</td>\n",
       "      <td>NCAA Could Keep Rules Banning Recruiting Incen...</td>\n",
       "      <td>The NCAA is working toward a solution for name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>News</td>\n",
       "      <td>/one-us-largest-unions-votes-make-amazon-prior...</td>\n",
       "      <td>One of U.S. Largest Unions Votes to Make Amazo...</td>\n",
       "      <td>The International Brotherhood of Teamsters, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Culture</td>\n",
       "      <td>/viral-therapist-shows-audacity-men-dating-app...</td>\n",
       "      <td>Viral Therapist Shows 'Audacity' of Men on Dat...</td>\n",
       "      <td>The TikTok community can't get enough of Katie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>Politics</td>\n",
       "      <td>/trump-calls-mcbrooms-michigan-election-report...</td>\n",
       "      <td>Trump Calls McBroom's Michigan Election Report...</td>\n",
       "      <td>In the statement, the former president also re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>News</td>\n",
       "      <td>/weed-cookies-that-resemble-famous-snack-brand...</td>\n",
       "      <td>Weed Cookies That Resemble Famous Snack Brands...</td>\n",
       "      <td>\"This is extremely discouraging and alarming t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                                url  \\\n",
       "0         U.S.  /fourth-stimulus-check-update-2000-monthly-pay...   \n",
       "1         News  /dave-portnoy-shouts-fox-business-host-air-ove...   \n",
       "2        World  /teacher-forced-remove-giant-swastika-pool-bot...   \n",
       "3         News  /mcconnell-biden-isnt-serious-about-bipartisan...   \n",
       "4         News  /hawley-condemns-canadas-arrest-church-leaders...   \n",
       "...        ...                                                ...   \n",
       "1495      News  /ncaa-could-keep-rules-banning-pay-play-recrui...   \n",
       "1496      News  /one-us-largest-unions-votes-make-amazon-prior...   \n",
       "1497   Culture  /viral-therapist-shows-audacity-men-dating-app...   \n",
       "1498  Politics  /trump-calls-mcbrooms-michigan-election-report...   \n",
       "1499      News  /weed-cookies-that-resemble-famous-snack-brand...   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Fourth Stimulus Check Update: $2,000 Monthly P...   \n",
       "1     Dave Portnoy Shouts At Fox Business Host On Ai...   \n",
       "2     Teacher Forced to Remove Giant Swastika from P...   \n",
       "3     McConnell Says Biden Isn't 'Serious' About Bip...   \n",
       "4     Hawley Condemns Canada's Clampdown on Churches...   \n",
       "...                                                 ...   \n",
       "1495  NCAA Could Keep Rules Banning Recruiting Incen...   \n",
       "1496  One of U.S. Largest Unions Votes to Make Amazo...   \n",
       "1497  Viral Therapist Shows 'Audacity' of Men on Dat...   \n",
       "1498  Trump Calls McBroom's Michigan Election Report...   \n",
       "1499  Weed Cookies That Resemble Famous Snack Brands...   \n",
       "\n",
       "                                                summary  \n",
       "0     If the petition hits its goal of 3 million sig...  \n",
       "1     \"You're being a moron,\" Barstool Sports founde...  \n",
       "2     A Brazilian history teacher has been forced to...  \n",
       "3     When asked if he would sign the infrastructure...  \n",
       "4     Missouri Senator Josh Hawley released a letter...  \n",
       "...                                                 ...  \n",
       "1495  The NCAA is working toward a solution for name...  \n",
       "1496  The International Brotherhood of Teamsters, wh...  \n",
       "1497  The TikTok community can't get enough of Katie...  \n",
       "1498  In the statement, the former president also re...  \n",
       "1499  \"This is extremely discouraging and alarming t...  \n",
       "\n",
       "[1500 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 14: Create a DataFrame with the lists\n",
    "dfl = {'category':category,'url':URL,'title':title,'summary':summary}\n",
    "df = pd.DataFrame(dfl)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "907BgEMXvwHU"
   },
   "source": [
    "### Step 15: Export the DataFrame as CSV\n",
    "Time to export this CSV so you can refer to it later in case you pause in the middle of this notebook.\n",
    "\n",
    "If you're on Google Colab, make sure your Drive is properly mounted first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ZowsErBsv8RV"
   },
   "outputs": [],
   "source": [
    "# Step 15: Export DataFrame as CSV\n",
    "df.to_csv(r'C:\\Users\\Aeriu\\Desktop\\CourseMaterials\\newsdf.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwiL53gdv7cM"
   },
   "source": [
    "# Test scrape one full article site\n",
    "Time to go into one article page for scraping. \n",
    "\n",
    "We'll go into the first article, and inspect the HTML elements. Again, don't worry if your first article is different from ours. \n",
    "\n",
    "The structure of the page generally is the same throughout, and looks something like this:\n",
    "\n",
    "![ArticleHTML](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTextSummarizer/ArticleHTML.png)\n",
    "\n",
    "In our example, you can take a look at:\n",
    "1. <font color='red'>div</font> that contains all the article content\n",
    "2. <font color='green'>p</font> that contains one paragraph of text\n",
    "3. <font color='blue'>div</font> that contains an ad (not shown)\n",
    "4. <font color='yellow'>p</font> that contains another paragraph of text\n",
    "5. <font color='red'>figure</font> that contains interactive content, e.g., a Twitter embed\n",
    "\n",
    "This goes on for the entire article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2wOy4FhcQbb"
   },
   "source": [
    "### Step 16: Get the URL for the first article\n",
    "Before we do anything,  let's get the full URL of the first article on your DataFrame from Step 14.\n",
    "\n",
    "The string in the url column goes something like \"/xxx-xxx-xxx-xxxxxx\", so you'll have to perform string concatenation with 'https://newsweek.com' to go to the article.\n",
    "\n",
    "Assign it to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>/fourth-stimulus-check-update-2000-monthly-pay...</td>\n",
       "      <td>Fourth Stimulus Check Update: $2,000 Monthly P...</td>\n",
       "      <td>If the petition hits its goal of 3 million sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>News</td>\n",
       "      <td>/dave-portnoy-shouts-fox-business-host-air-ove...</td>\n",
       "      <td>Dave Portnoy Shouts At Fox Business Host On Ai...</td>\n",
       "      <td>\"You're being a moron,\" Barstool Sports founde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>World</td>\n",
       "      <td>/teacher-forced-remove-giant-swastika-pool-bot...</td>\n",
       "      <td>Teacher Forced to Remove Giant Swastika from P...</td>\n",
       "      <td>A Brazilian history teacher has been forced to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>News</td>\n",
       "      <td>/mcconnell-biden-isnt-serious-about-bipartisan...</td>\n",
       "      <td>McConnell Says Biden Isn't 'Serious' About Bip...</td>\n",
       "      <td>When asked if he would sign the infrastructure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>News</td>\n",
       "      <td>/hawley-condemns-canadas-arrest-church-leaders...</td>\n",
       "      <td>Hawley Condemns Canada's Clampdown on Churches...</td>\n",
       "      <td>Missouri Senator Josh Hawley released a letter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>News</td>\n",
       "      <td>/ncaa-could-keep-rules-banning-pay-play-recrui...</td>\n",
       "      <td>NCAA Could Keep Rules Banning Recruiting Incen...</td>\n",
       "      <td>The NCAA is working toward a solution for name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>News</td>\n",
       "      <td>/one-us-largest-unions-votes-make-amazon-prior...</td>\n",
       "      <td>One of U.S. Largest Unions Votes to Make Amazo...</td>\n",
       "      <td>The International Brotherhood of Teamsters, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Culture</td>\n",
       "      <td>/viral-therapist-shows-audacity-men-dating-app...</td>\n",
       "      <td>Viral Therapist Shows 'Audacity' of Men on Dat...</td>\n",
       "      <td>The TikTok community can't get enough of Katie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>Politics</td>\n",
       "      <td>/trump-calls-mcbrooms-michigan-election-report...</td>\n",
       "      <td>Trump Calls McBroom's Michigan Election Report...</td>\n",
       "      <td>In the statement, the former president also re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>News</td>\n",
       "      <td>/weed-cookies-that-resemble-famous-snack-brand...</td>\n",
       "      <td>Weed Cookies That Resemble Famous Snack Brands...</td>\n",
       "      <td>\"This is extremely discouraging and alarming t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                                url  \\\n",
       "0         U.S.  /fourth-stimulus-check-update-2000-monthly-pay...   \n",
       "1         News  /dave-portnoy-shouts-fox-business-host-air-ove...   \n",
       "2        World  /teacher-forced-remove-giant-swastika-pool-bot...   \n",
       "3         News  /mcconnell-biden-isnt-serious-about-bipartisan...   \n",
       "4         News  /hawley-condemns-canadas-arrest-church-leaders...   \n",
       "...        ...                                                ...   \n",
       "1495      News  /ncaa-could-keep-rules-banning-pay-play-recrui...   \n",
       "1496      News  /one-us-largest-unions-votes-make-amazon-prior...   \n",
       "1497   Culture  /viral-therapist-shows-audacity-men-dating-app...   \n",
       "1498  Politics  /trump-calls-mcbrooms-michigan-election-report...   \n",
       "1499      News  /weed-cookies-that-resemble-famous-snack-brand...   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Fourth Stimulus Check Update: $2,000 Monthly P...   \n",
       "1     Dave Portnoy Shouts At Fox Business Host On Ai...   \n",
       "2     Teacher Forced to Remove Giant Swastika from P...   \n",
       "3     McConnell Says Biden Isn't 'Serious' About Bip...   \n",
       "4     Hawley Condemns Canada's Clampdown on Churches...   \n",
       "...                                                 ...   \n",
       "1495  NCAA Could Keep Rules Banning Recruiting Incen...   \n",
       "1496  One of U.S. Largest Unions Votes to Make Amazo...   \n",
       "1497  Viral Therapist Shows 'Audacity' of Men on Dat...   \n",
       "1498  Trump Calls McBroom's Michigan Election Report...   \n",
       "1499  Weed Cookies That Resemble Famous Snack Brands...   \n",
       "\n",
       "                                                summary  \n",
       "0     If the petition hits its goal of 3 million sig...  \n",
       "1     \"You're being a moron,\" Barstool Sports founde...  \n",
       "2     A Brazilian history teacher has been forced to...  \n",
       "3     When asked if he would sign the infrastructure...  \n",
       "4     Missouri Senator Josh Hawley released a letter...  \n",
       "...                                                 ...  \n",
       "1495  The NCAA is working toward a solution for name...  \n",
       "1496  The International Brotherhood of Teamsters, wh...  \n",
       "1497  The TikTok community can't get enough of Katie...  \n",
       "1498  In the statement, the former president also re...  \n",
       "1499  \"This is extremely discouraging and alarming t...  \n",
       "\n",
       "[1500 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "x6mXeSWSpSaV",
    "outputId": "f0cf19e7-1fc7-4063-8296-7995bacec513"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://newsweek.com/fourth-stimulus-check-update-2000-monthly-payment-petition-hits-24-million-signatures-1603975'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 16: Get the URL for the first article\n",
    "nw = 'https://newsweek.com'\n",
    "firsturl = nw + df['url'][0]\n",
    "firsturl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e05vLjsJdi-p"
   },
   "source": [
    "### Step 17: Repeat Steps 2-4 on the first article\n",
    "Let's repeat Steps 2-4 on the article URL. To recap, you'll need to:\n",
    "1. Make a GET request\n",
    "2. Load the GET response into a BeatifulSoup object\n",
    "3. Check out the HTML of the article page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AfzwUarmpZTS",
    "outputId": "fd8c23ee-05a5-42bc-da2a-af524dea0211"
   },
   "outputs": [],
   "source": [
    "# Step 17a: Perform a GET request on the article URL\n",
    "response = requests.get(firsturl,headers=headers)\n",
    "response\n",
    "# Step 17b: Load the response into a BeautifulSoup object, in a new variable\n",
    "firstsoup = BeautifulSoup(response.text,'html.parser')\n",
    "# Step 17c: Check out the HTML in the BeautifulSoup\n",
    "#firstsoup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlC-GlM9fhaS"
   },
   "source": [
    "### Step 18: Find the div containing all article content\n",
    "We'll look for the <font color='red'>div</font> that contains all of our article text (scroll up a bit for reference).\n",
    "\n",
    "More specifically, look for the div that belongs to a class named 'article-body v_text paywall'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6I7RxNVp2cs",
    "outputId": "59f67690-3a41-47b3-ebee-d8072bdba15f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div class=\"article-body v_text paywall\">\\n <p>\\n  A petition for monthly stimulus checks surpassed 2.4 million signatures on Thursday, putting it only about 600,000 signatures away from its target goal of 3 million.\\n </p>\\n <p>\\n  Stephanie Bonin, a Denver restaurant owner, started the petition last year when the pandemic forced the closure of businesses across the country. It\\'s had a steady stream of supporters and despite states reopening businesses and lifting restrictions, people continue to sign the petition that urges\\n  <a data-sys=\"1\" href=\"https://www.newsweek.com/topic/congress\">\\n   Congress\\n  </a>\\n  to take additional action.\\n </p>\\n <p>\\n  The\\n  <a href=\"https://www.change.org/p/give-2000-month-to-every-american-moneyforthepeople-covid19\" rel=\"nofollow\">\\n   petition\\n  </a>\\n  calls for Congress to pass relief that would send out $2,000 monthly payments to adults and $1,000 payments for kids. It urges legislators to continue the payments for the \"duration of the crisis\" to help people who were financially impacted by the pandemic pay their rent and put food on the table.\\n </p>\\n <p>\\n  If the petition reaches its goal of 3 million signatures, it will be one of the most-signed petitions on the Change.org website. In December, Bonin was recognized for having started one of the top 10 petitions that changed the world.\\n </p>\\n <p>\\n  \"The last three stimulus checks and additional aid like the monthly child tax credit were birthed out of necessity and have had a significant impact,\" Stephanie said in a statement. \"But issues of economic disparity in our country were here before COVID-19 and I don\\'t want to move backwards just because the health pandemic is getting under control.\"\\n </p>\\n <figure class=\"imageBox\" style=\"\">\\n  <div class=\"innerBox\" style=\"height:0;padding-bottom:69.1214%\">\\n   <picture class=\"mapping-embed\" height=\"546\" width=\"790\">\\n    <source media=\"(min-width: 992px)\" srcset=\"https://d.newsweek.com/en/full/1829666/joe-biden-stimulus-check-monthly-fourth.webp?w=790&amp;f=c12490ef74324a95eaed27aa4c2d5c7d 1x\" type=\"image/webp\"/>\\n    <source media=\"(min-width: 992px)\" srcset=\"https://d.newsweek.com/en/full/1829666/joe-biden-stimulus-check-monthly-fourth.jpg?w=790&amp;f=c12490ef74324a95eaed27aa4c2d5c7d 1x\" type=\"image/jpeg\"/>\\n    <source media=\"(min-width: 768px)\" srcset=\"https://d.newsweek.com/en/full/1829666/joe-biden-stimulus-check-monthly-fourth.webp?w=900&amp;f=70b9c4228ed2e83ba6829b054e1bf8ab 1x\" type=\"image/webp\"/>\\n    <source media=\"(min-width: 768px)\" srcset=\"https://d.newsweek.com/en/full/1829666/joe-biden-stimulus-check-monthly-fourth.jpg?w=900&amp;f=70b9c4228ed2e83ba6829b054e1bf8ab 1x\" type=\"image/jpeg\"/>\\n    <source media=\"(min-width: 481px)\" srcset=\"https://d.newsweek.com/en/full/1829666/joe-biden-stimulus-check-monthly-fourth.webp?w=790&amp;f=c12490ef74324a95eaed27aa4c2d5c7d 1x\" type=\"image/webp\"/>\\n    <source media=\"(min-width: 481px)\" srcset=\"https://d.newsweek.com/en/full/1829666/joe-biden-stimulus-check-monthly-fourth.jpg?w=790&amp;f=c12490ef74324a95eaed27aa4c2d5c7d 1x\" type=\"image/jpeg\"/>\\n    <source media=\"(min-width: 0px)\" srcset=\"https://d.newsweek.com/en/full/1829666/joe-biden-stimulus-check-monthly-fourth.webp?w=450&amp;f=158c86274e509eb7e6369d0d65ee7410 1x\" type=\"image/webp\"/>\\n    <source media=\"(min-width: 0px)\" srcset=\"https://d.newsweek.com/en/full/1829666/joe-biden-stimulus-check-monthly-fourth.jpg?w=450&amp;f=158c86274e509eb7e6369d0d65ee7410 1x\" type=\"image/jpeg\"/>\\n    <source srcset=\"https://d.newsweek.com/en/full/1829666/joe-biden-stimulus-check-monthly-fourth.webp?w=790&amp;f=c12490ef74324a95eaed27aa4c2d5c7d\" type=\"image/webp\"/>\\n    <img alt=\"joe biden stimulus check monthly fourth \" class=\"mapping-embed imgPhoto\" height=\"546\" id=\"i1829666\" loading=\"lazy\" src=\"https://d.newsweek.com/en/full/1829666/joe-biden-stimulus-check-monthly-fourth.jpg?w=790&amp;f=c12490ef74324a95eaed27aa4c2d5c7d\" width=\"790\"/>\\n   </picture>\\n  </div>\\n  <figcaption class=\"caption\">\\n   <span class=\"cap\">\\n    A Change.org petition calling for $2,000 monthly payments surpassed 2.4 million signatures on Thursday. President Joe Biden delivers remarks on the Senate\\'s bipartisan infrastructure deal at the White House on June 24, 2021 in Washington, DC. Biden said both sides made compromises on the nearly $1 trillion infrastructure bill (Photo by Kevin Dietsch/Getty Images)\\n   </span>\\n   <span class=\"credit\">\\n    Kevin Dietsch/Getty Images\\n   </span>\\n  </figcaption>\\n </figure>\\n <p>\\n  When the petition passed 2.3 million signatures, Bonin said it signified 2.3 million people agreeing that \"we need to take care of one another for the long haul.\"\\n </p>\\n <p>\\n  At least 80 lawmakers support another round of direct payments and some are pushing for President\\n  <a data-sys=\"1\" href=\"https://www.newsweek.com/topic/joe-biden\">\\n   Joe Biden\\n  </a>\\n  to enact automatic stabilizers. If automatic stabilizers were in place, direct payments would be sent out whenever predetermined economic conditions were met. Often tied to employment, an option would be to send out payments whenever unemployment reached a certain level. When employment rose, the payments would automatically end.\\n </p>\\n <figure class=\"block block-ibtg-article fA\" data-gtm-action=\"Click\" data-gtm-category=\"Related In-Text A\">\\n  <div class=\"content\">\\n   <div class=\"v_text v_embed\" id=\"v_embed\">\\n    <div class=\"related2 style2 id\">\\n     <div class=\"block-title\">\\n      <span>\\n       Read more\\n      </span>\\n     </div>\\n     <ul>\\n      <li>\\n       <a data-gtm-action=\"Click\" data-gtm-category=\"Related In-Text A\" data-gtm-label=\"Article 1\" href=\"/caitlyn-jenner-hits-gavin-newsoms-stimulus-checks-calls-them-recall-rebates-1595148\">\\n        <span class=\"bullet\">\\n        </span>\\n        Caitlyn Jenner Hits Newsom\\'s Stimulus Checks, Calls Them \\'Recall Rebates\\'\\n       </a>\\n      </li>\\n      <li>\\n       <a data-gtm-action=\"Click\" data-gtm-category=\"Related In-Text A\" data-gtm-label=\"Article 2\" href=\"/fourth-stimulus-check-why-some-may-not-eligible-if-congress-passes-more-relief-1593719\">\\n        <span class=\"bullet\">\\n        </span>\\n        Fourth Stimulus Check: Why Some May Not Be Eligible if There\\'s More Relief\\n       </a>\\n      </li>\\n      <li>\\n       <a data-gtm-action=\"Click\" data-gtm-category=\"Related In-Text A\" data-gtm-label=\"Article 3\" href=\"/automatic-stimulus-checks-white-house-senators-weighing-economic-triggers-future-relief-1589663\">\\n        <span class=\"bullet\">\\n        </span>\\n        Automatic Stimulus Checks? Legislators Weighing Economic Triggers\\n       </a>\\n      </li>\\n     </ul>\\n    </div>\\n   </div>\\n  </div>\\n </figure>\\n <p>\\n  Biden supports automatic stabilizers for expanded unemployment payments but has largely remained quiet on the subject of stimulus checks. While the White House is open to a plan if Congress puts one forward, White House press secretary\\n  <a data-sys=\"1\" href=\"https://www.newsweek.com/topic/jen-psaki\">\\n   Jen Psaki\\n  </a>\\n  noted that the measure is not free.\\n </p>\\n <p>\\n  A costly relief measure, additional stimulus checks are unlikely to garner support among\\n  <a data-sys=\"1\" href=\"https://www.newsweek.com/topic/republicans\">\\n   Republicans\\n  </a>\\n  . The GOP pushed back on the American Rescue Plan, a $1.8 trillion relief package that passed along party lines in March, because they wanted more targeted relief. Given the amount of states that are lifting restrictions and allowing businesses to reopen, Republicans are likely to be even more opposed to additional direct relief than they were a few months ago.\\n </p>\\n</div>'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 18: Get the div\n",
    "firstsoup.find('div',{'class':'article-body v_text paywall'}).prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paOPlW-Af-cC"
   },
   "source": [
    "### Step 19: Get all p only\n",
    "As you scroll through the article HTML, what do you notice? The text can found in only <font color='green'>p</font> HTML tags.\n",
    "\n",
    "Use the .find_all method to find only <font color='green'>p</font>.\n",
    "\n",
    "You'll end up with a list, something like this:\n",
    "![ListOfParagraphs](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTextSummarizer/ListOfParagraphs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtTmAZIpp-RY",
    "outputId": "c5dc3d19-cc9d-4aa8-8ab2-f6fd87a5ac5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>A petition for monthly stimulus checks surpassed 2.4 million signatures on Thursday, putting it only about 600,000 signatures away from its target goal of 3 million.</p>,\n",
       " <p>Stephanie Bonin, a Denver restaurant owner, started the petition last year when the pandemic forced the closure of businesses across the country. It's had a steady stream of supporters and despite states reopening businesses and lifting restrictions, people continue to sign the petition that urges <a data-sys=\"1\" href=\"https://www.newsweek.com/topic/congress\">Congress</a> to take additional action.</p>,\n",
       " <p>The <a href=\"https://www.change.org/p/give-2000-month-to-every-american-moneyforthepeople-covid19\" rel=\"nofollow\">petition</a> calls for Congress to pass relief that would send out $2,000 monthly payments to adults and $1,000 payments for kids. It urges legislators to continue the payments for the \"duration of the crisis\" to help people who were financially impacted by the pandemic pay their rent and put food on the table.</p>,\n",
       " <p>If the petition reaches its goal of 3 million signatures, it will be one of the most-signed petitions on the Change.org website. In December, Bonin was recognized for having started one of the top 10 petitions that changed the world.</p>,\n",
       " <p>\"The last three stimulus checks and additional aid like the monthly child tax credit were birthed out of necessity and have had a significant impact,\" Stephanie said in a statement. \"But issues of economic disparity in our country were here before COVID-19 and I don't want to move backwards just because the health pandemic is getting under control.\"</p>,\n",
       " <p>When the petition passed 2.3 million signatures, Bonin said it signified 2.3 million people agreeing that \"we need to take care of one another for the long haul.\"</p>,\n",
       " <p>At least 80 lawmakers support another round of direct payments and some are pushing for President <a data-sys=\"1\" href=\"https://www.newsweek.com/topic/joe-biden\">Joe Biden</a> to enact automatic stabilizers. If automatic stabilizers were in place, direct payments would be sent out whenever predetermined economic conditions were met. Often tied to employment, an option would be to send out payments whenever unemployment reached a certain level. When employment rose, the payments would automatically end.</p>,\n",
       " <p>Biden supports automatic stabilizers for expanded unemployment payments but has largely remained quiet on the subject of stimulus checks. While the White House is open to a plan if Congress puts one forward, White House press secretary <a data-sys=\"1\" href=\"https://www.newsweek.com/topic/jen-psaki\">Jen Psaki</a> noted that the measure is not free.</p>,\n",
       " <p>A costly relief measure, additional stimulus checks are unlikely to garner support among <a data-sys=\"1\" href=\"https://www.newsweek.com/topic/republicans\">Republicans</a>. The GOP pushed back on the American Rescue Plan, a $1.8 trillion relief package that passed along party lines in March, because they wanted more targeted relief. Given the amount of states that are lifting restrictions and allowing businesses to reopen, Republicans are likely to be even more opposed to additional direct relief than they were a few months ago.</p>,\n",
       " <p><strong>You have <span>4</span> free articles remaining this month</strong></p>,\n",
       " <p class=\"non-subscriber\">Sign-up to our daily newsletter for more articles like this + access to 5 extra articles</p>,\n",
       " <p><strong>To continue reading login or create an account.</strong></p>,\n",
       " <p class=\"non-subscriber\"> No subscription required.</p>,\n",
       " <p>\n",
       " Daily news headlines &amp; detailed briefings enjoyed by half a million readers.</p>,\n",
       " <p class=\"copyright\">© 2021 NEWSWEEK DIGITAL LLC</p>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 19: Find all p tags in your BeautifulSoup\n",
    "firstsoup.find_all('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHY2U_-ehVTS"
   },
   "source": [
    "### Step 20: Join all of the text together\n",
    "You have a list of p tags containing a mix of text and URLs.\n",
    "\n",
    "Extract all of the text from the p tags with the .text attribute and join them together into a long string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEE8D871hmx4"
   },
   "source": [
    "<details>\n",
    "<summary>Click here once for a small hint</summary>\n",
    "<div><strong>You'll need a for loop so you can append only the text from the p tags into a list, and a .join method at the end to join all of the strings in the list into a larger string.</strong></div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(str, pandas.core.series.Series)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(firsturl),type(urllist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = requests.get(urllist,headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-8AhASpEqOoz",
    "outputId": "6ec274d6-dcc9-41e4-a031-e191f1932f70"
   },
   "outputs": [],
   "source": [
    "# Step 20: Join all of the text together\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}\n",
    "nw = 'https://newsweek.com'\n",
    "urllist = nw + df['url']\n",
    "for links in urllist:\n",
    "    response = requests.get(links,headers=headers)\n",
    "newsoup = BeautifulSoup(response.text,'html.parser')\n",
    "ptext = []\n",
    "ptextlong = []\n",
    "for div in newsoup.find_all('p'):\n",
    "    ptext.append(div.text)\n",
    "ptextlong.append(' '.join(ptext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 1)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ptext),len(ptextlong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Weed cookies resembling Oreos and Chips Ahoy brand cookies sold in Long Beach, New York, are prompting concerns over \"targeting children,\" New York Senator Todd Kaminsky said. These treats containing synthetic marijuana are marketed as \"Double Stuf Stoneos\" and \"Trips Ahoy\" with packaging extremely similar to the famous snack brands they appear to be based on, according to WABC. They were found at a wellness store named Dr. Nature in Long Beach. @pconnection1  So how far is too far on Hemp-Extract products? Oreo vs Stoneo, and Chips Ahoy vs Trips Ahoy.#HempProduct#WeedLovers pic.twitter.com/bUWeglp4Dv \"This is extremely discouraging and alarming to know that these products could end up in the hands of our young children who think they\\'re having an afternoon snack. That cannot be allowed,\" he also said. The cookies contain Delta-8, a psychoactive, hemp-based substance found in cannabis plants that is legal in New York. Dr. Nature\\'s shop owner reportedly did not know the packaged cookies contained the marijuana ingredient, according to officials. Police said that when they spoke with the owner, he removed the treats from the shelf, according to WABC. \"He was actually proactive about it,\" a police officer said. Kaminsky and local Long Island officials are calling on the New York State Department of Health to immediately ban Delta-8. Delta-8 THC is a drug sold in stores right NOW . It is also being marketed aggressively to kids. Today, I stand with the Long Beach community, @CurranNassau @judygriffinny @MissyMillerNY urging @HealthNYGov to ban Delta-8 and keep our kids safe. pic.twitter.com/iRDvJlxp6s \"Due to Delta-8 THC being naturally found in hemp, retailers have exploited this loophole since hemp is not illegal,\" said a letter addressed to the New York Health Department\\'s Commissioner Howard Zucker signed by Kaminsky and three other local officials on Wednesday. \"Companies are taking advantage of the loophole by putting their products in packaging that is clearly targeting children in a very dangerous way,\" said Kaminsky at a press conference with other local officials Tuesday. \"This means that many unregulated cigarette stores and \\'health products\\' retailers sell products containing Delta-8 THC,\" the letter said. It added the state is still \"working on creating a state-licensed and state-regulated adult marijuana use industry\" that \"includes specific provisions limiting youth access.\" New York Governor Andrew Cuomo signed legislation legalizing recreational marijuana on April 30. \"Our new state law even requires the new regulations to look at rules restricting marketing and advertising to youth,\" the letter said. \"Yet, to allow a hemp compound so similar to marijuana to go unregulated is ridiculous and dangerous.\" The letter is in response to the health department\\'s Cannabinoid Hemp program\\'s proposed revised regulations as part of the department\\'s overall regulations that are subject to public comment until July 19, said Jill Montag, the state health department\\'s communications director, wrote to Newsweek. \"After such time, the Department will assess all comments and if no further changes are necessary, adopt the regulations as written, at which time the prohibition on products manufactured with Delta 8 created through isomerization will be immediately effective,\" she said. \"DOH has the responsibility to protect Long Islanders by taking swift action to prohibit the unregulated sale of products containing Delta-8,\" the letter concluded. Newsweek reached out to Kaminsky for additional comment but did not hear back in time for publication. You have 4 free articles remaining this month Sign-up to our daily newsletter for more articles like this + access to 5 extra articles To continue reading login or create an account.  No subscription required. \\nDaily news headlines & detailed briefings enjoyed by half a million readers. © 2021 NEWSWEEK DIGITAL LLC']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptextlong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ptext),len(ptextlong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Weed cookies resembling Oreos and Chips Ahoy brand cookies sold in Long Beach, New York, are prompting concerns over \"targeting children,\" New York Senator Todd Kaminsky said.',\n",
       " 'These treats containing synthetic marijuana are marketed as \"Double Stuf Stoneos\" and \"Trips Ahoy\" with packaging extremely similar to the famous snack brands they appear to be based on, according to WABC. They were found at a wellness store named Dr. Nature in Long Beach.',\n",
       " '@pconnection1  So how far is too far on Hemp-Extract products? Oreo vs Stoneo, and Chips Ahoy vs Trips Ahoy.#HempProduct#WeedLovers pic.twitter.com/bUWeglp4Dv',\n",
       " '\"This is extremely discouraging and alarming to know that these products could end up in the hands of our young children who think they\\'re having an afternoon snack. That cannot be allowed,\" he also said.',\n",
       " 'The cookies contain Delta-8, a psychoactive, hemp-based substance found in cannabis plants that is legal in New York.',\n",
       " \"Dr. Nature's shop owner reportedly did not know the packaged cookies contained the marijuana ingredient, according to officials.\",\n",
       " 'Police said that when they spoke with the owner, he removed the treats from the shelf, according to WABC.',\n",
       " '\"He was actually proactive about it,\" a police officer said.',\n",
       " 'Kaminsky and local Long Island officials are calling on the New York State Department of Health to immediately ban Delta-8.',\n",
       " 'Delta-8 THC is a drug sold in stores right NOW . It is also being marketed aggressively to kids. Today, I stand with the Long Beach community, @CurranNassau @judygriffinny @MissyMillerNY urging @HealthNYGov to ban Delta-8 and keep our kids safe. pic.twitter.com/iRDvJlxp6s',\n",
       " '\"Due to Delta-8 THC being naturally found in hemp, retailers have exploited this loophole since hemp is not illegal,\" said a letter addressed to the New York Health Department\\'s Commissioner Howard Zucker signed by Kaminsky and three other local officials on Wednesday.',\n",
       " '\"Companies are taking advantage of the loophole by putting their products in packaging that is clearly targeting children in a very dangerous way,\" said Kaminsky at a press conference with other local officials Tuesday.',\n",
       " '\"This means that many unregulated cigarette stores and \\'health products\\' retailers sell products containing Delta-8 THC,\" the letter said.',\n",
       " 'It added the state is still \"working on creating a state-licensed and state-regulated adult marijuana use industry\" that \"includes specific provisions limiting youth access.\"',\n",
       " 'New York Governor Andrew Cuomo signed legislation legalizing recreational marijuana on April 30.',\n",
       " '\"Our new state law even requires the new regulations to look at rules restricting marketing and advertising to youth,\" the letter said. \"Yet, to allow a hemp compound so similar to marijuana to go unregulated is ridiculous and dangerous.\"',\n",
       " \"The letter is in response to the health department's Cannabinoid Hemp program's proposed revised regulations as part of the department's overall regulations that are subject to public comment until July 19, said Jill Montag, the state health department's communications director, wrote to Newsweek.\",\n",
       " '\"After such time, the Department will assess all comments and if no further changes are necessary, adopt the regulations as written, at which time the prohibition on products manufactured with Delta 8 created through isomerization will be immediately effective,\" she said.',\n",
       " '\"DOH has the responsibility to protect Long Islanders by taking swift action to prohibit the unregulated sale of products containing Delta-8,\" the letter concluded.',\n",
       " 'Newsweek reached out to Kaminsky for additional comment but did not hear back in time for publication.',\n",
       " 'You have 4 free articles remaining this month',\n",
       " 'Sign-up to our daily newsletter for more articles like this + access to 5 extra articles',\n",
       " 'To continue reading login or create an account.',\n",
       " ' No subscription required.',\n",
       " '\\nDaily news headlines & detailed briefings enjoyed by half a million readers.',\n",
       " '© 2021 NEWSWEEK DIGITAL LLC']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A petition for monthly stimulus checks surpassed 2.4 million signatures on Thursday, putting it only about 600,000 signatures away from its target goal of 3 million. Stephanie Bonin, a Denver restaurant owner, started the petition last year when the pandemic forced the closure of businesses across the country. It\\'s had a steady stream of supporters and despite states reopening businesses and lifting restrictions, people continue to sign the petition that urges Congress to take additional action. The petition calls for Congress to pass relief that would send out $2,000 monthly payments to adults and $1,000 payments for kids. It urges legislators to continue the payments for the \"duration of the crisis\" to help people who were financially impacted by the pandemic pay their rent and put food on the table. If the petition reaches its goal of 3 million signatures, it will be one of the most-signed petitions on the Change.org website. In December, Bonin was recognized for having started one of the top 10 petitions that changed the world. \"The last three stimulus checks and additional aid like the monthly child tax credit were birthed out of necessity and have had a significant impact,\" Stephanie said in a statement. \"But issues of economic disparity in our country were here before COVID-19 and I don\\'t want to move backwards just because the health pandemic is getting under control.\" When the petition passed 2.3 million signatures, Bonin said it signified 2.3 million people agreeing that \"we need to take care of one another for the long haul.\" At least 80 lawmakers support another round of direct payments and some are pushing for President Joe Biden to enact automatic stabilizers. If automatic stabilizers were in place, direct payments would be sent out whenever predetermined economic conditions were met. Often tied to employment, an option would be to send out payments whenever unemployment reached a certain level. When employment rose, the payments would automatically end. Biden supports automatic stabilizers for expanded unemployment payments but has largely remained quiet on the subject of stimulus checks. While the White House is open to a plan if Congress puts one forward, White House press secretary Jen Psaki noted that the measure is not free. A costly relief measure, additional stimulus checks are unlikely to garner support among Republicans. The GOP pushed back on the American Rescue Plan, a $1.8 trillion relief package that passed along party lines in March, because they wanted more targeted relief. Given the amount of states that are lifting restrictions and allowing businesses to reopen, Republicans are likely to be even more opposed to additional direct relief than they were a few months ago. You have 4 free articles remaining this month Sign-up to our daily newsletter for more articles like this + access to 5 extra articles To continue reading login or create an account.  No subscription required. \\nDaily news headlines & detailed briefings enjoyed by half a million readers. © 2021 NEWSWEEK DIGITAL LLC']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptextlong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzyJielEiPKx"
   },
   "source": [
    "# Scrape all 1,500 articles\n",
    "Now that you know how to scrape the text from one article, it's time to loop through the url column of your DataFrame from Step 14."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_m5ZgB7i3rF"
   },
   "source": [
    "### Step 21: Scrape all articles from url column\n",
    "Create a list containing the text from all 1,500 articles. \n",
    "\n",
    "It's repeating Steps 16-20, but appending the results into a list. \n",
    "\n",
    "Use a try-except conditiional to catch any unexpected errors, and return None. Our list MUST have 1,500 items in it.\n",
    "\n",
    "<strong>This step will take between 6 to 10 minutes - be patient.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "RFT7dgSgqXWx"
   },
   "outputs": [],
   "source": [
    "# Step 21: Scrape the articles found in the url column\n",
    "ptext = []\n",
    "ptextlong = []\n",
    "nw = 'https://newsweek.com'\n",
    "for i in df:\n",
    "    ptext.append(nw + df['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0       https://newsweek.com/fourth-stimulus-check-upd...\n",
       " 1       https://newsweek.com/dave-portnoy-shouts-fox-b...\n",
       " 2       https://newsweek.com/teacher-forced-remove-gia...\n",
       " 3       https://newsweek.com/mcconnell-biden-isnt-seri...\n",
       " 4       https://newsweek.com/hawley-condemns-canadas-a...\n",
       "                               ...                        \n",
       " 1495    https://newsweek.com/ncaa-could-keep-rules-ban...\n",
       " 1496    https://newsweek.com/one-us-largest-unions-vot...\n",
       " 1497    https://newsweek.com/viral-therapist-shows-aud...\n",
       " 1498    https://newsweek.com/trump-calls-mcbrooms-mich...\n",
       " 1499    https://newsweek.com/weed-cookies-that-resembl...\n",
       " Name: url, Length: 1500, dtype: object,\n",
       " 0       https://newsweek.com/fourth-stimulus-check-upd...\n",
       " 1       https://newsweek.com/dave-portnoy-shouts-fox-b...\n",
       " 2       https://newsweek.com/teacher-forced-remove-gia...\n",
       " 3       https://newsweek.com/mcconnell-biden-isnt-seri...\n",
       " 4       https://newsweek.com/hawley-condemns-canadas-a...\n",
       "                               ...                        \n",
       " 1495    https://newsweek.com/ncaa-could-keep-rules-ban...\n",
       " 1496    https://newsweek.com/one-us-largest-unions-vot...\n",
       " 1497    https://newsweek.com/viral-therapist-shows-aud...\n",
       " 1498    https://newsweek.com/trump-calls-mcbrooms-mich...\n",
       " 1499    https://newsweek.com/weed-cookies-that-resembl...\n",
       " Name: url, Length: 1500, dtype: object,\n",
       " 0       https://newsweek.com/fourth-stimulus-check-upd...\n",
       " 1       https://newsweek.com/dave-portnoy-shouts-fox-b...\n",
       " 2       https://newsweek.com/teacher-forced-remove-gia...\n",
       " 3       https://newsweek.com/mcconnell-biden-isnt-seri...\n",
       " 4       https://newsweek.com/hawley-condemns-canadas-a...\n",
       "                               ...                        \n",
       " 1495    https://newsweek.com/ncaa-could-keep-rules-ban...\n",
       " 1496    https://newsweek.com/one-us-largest-unions-vot...\n",
       " 1497    https://newsweek.com/viral-therapist-shows-aud...\n",
       " 1498    https://newsweek.com/trump-calls-mcbrooms-mich...\n",
       " 1499    https://newsweek.com/weed-cookies-that-resembl...\n",
       " Name: url, Length: 1500, dtype: object,\n",
       " 0       https://newsweek.com/fourth-stimulus-check-upd...\n",
       " 1       https://newsweek.com/dave-portnoy-shouts-fox-b...\n",
       " 2       https://newsweek.com/teacher-forced-remove-gia...\n",
       " 3       https://newsweek.com/mcconnell-biden-isnt-seri...\n",
       " 4       https://newsweek.com/hawley-condemns-canadas-a...\n",
       "                               ...                        \n",
       " 1495    https://newsweek.com/ncaa-could-keep-rules-ban...\n",
       " 1496    https://newsweek.com/one-us-largest-unions-vot...\n",
       " 1497    https://newsweek.com/viral-therapist-shows-aud...\n",
       " 1498    https://newsweek.com/trump-calls-mcbrooms-mich...\n",
       " 1499    https://newsweek.com/weed-cookies-that-resembl...\n",
       " Name: url, Length: 1500, dtype: object]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6K-rwV1jv85"
   },
   "source": [
    "### Step 22: Create full_text column\n",
    "With the list you got from Step 21, create a new column named full_text.\n",
    "\n",
    "You'll end up with something like this:\n",
    "\n",
    "![FullTextColumn](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTextSummarizer/FullTextColumn.png)\n",
    "You'll have:\n",
    "1. 1,500 rows\n",
    "2. 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "qLmszh17je2x",
    "outputId": "8c9454ae-ba05-4aa4-b93a-b014dbcc13cf"
   },
   "outputs": [],
   "source": [
    "# Step 22: Create full_text column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zn8L-lgdk8Yc"
   },
   "source": [
    "### Step 23: Export the DataFrame\n",
    "With the DataFrame complete with both the summary and full text of the article, let's export the DataFrame for subsequent Parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVdoCATwEk7j"
   },
   "outputs": [],
   "source": [
    "# Step 23: Export the DataFrame as CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dK1YApmNmn0H"
   },
   "source": [
    "# End of Part I\n",
    "Phew, what a Part. Hope you enjoyed the data collection segment. The thing about web scraping is that once you get the hang of it, you'll feel like you're wielding a new superpower.\n",
    "\n",
    "In this Part, you scraped both the listings page of Newsweek and the article text within. \n",
    "\n",
    "In the next Part, we'll start with extractive summarization and summarize the 1,500 articles that you've scraped.\n",
    "\n",
    "<strong>Note: we'll be using our own dataset from here onwards - if you'd like to use the same dataset as us for consistent reference, just click <a href=\"https://uplevelsg.s3-ap-southeast-1.amazonaws.com/df_part_i.csv\">here</a> to download the CSV.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project Text Summarizer (Part I)",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
